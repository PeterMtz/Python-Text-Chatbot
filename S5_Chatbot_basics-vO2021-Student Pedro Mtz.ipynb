{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "  <img src=\"http://oci02.img.iteso.mx/identidad_de_instancia_2018/ITESO/Logos%20ITESO/Logo-ITESO-Principal.jpg\" style=\"width:280px;height:90px; vertical-align:middle; float:right\" align=\"middle\">\n",
    "</div>\n",
    "\n",
    "# Proyecto 5 - Chatbot de Texto\n",
    "## _Minería de Textos_\n",
    "### Author: Pedro Martinez\n",
    "### Professor: Mildreth Alcaraz Mejia\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1. CREACIÓN E IMPORTACIÓN DEL CORPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Importar texto para obtener una sola cadena con todo el texto: 'Aquí va todo el texto. Aunque sean muchas oraciones separadas con comas o puntos. Se le llama texto plano o \"raw text\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El curso de Minería de Textos tiene 8 créditos que se traduce a un tiempo de dedicación de 8 horas totales repartidas en 3 horas BCD y 5 horas TIE.\\nBCD significa o es igual a Bajo Conducción Docente. \\nTIE significa o es igual a Tiempo Independiente del Estudiante.\\nLa CLAVE DE ASIGNATURA es MSC2499A.\\nEste curso pertenece al programa académico de posgrado de la Maestría en Sistemas Computacionales, en el departamento de Electrónica, Sistemas e Informática.\\nEl horario del curso es cada Lunes de 7pm a 10pm.\\nEl curso pertenece a la COORDINACIÓN DOCENTE de Aprendizaje Automático.\\nEl curso se imparte en el idioma Español.\\nLa profesora que imparte el curso durante este periodo es la Doctora Mildreth Isadora Alcaraz Mejía, Profesora Titular.\\nEl correo de la profesora es mildreth@iteso.mx.\\nLa página web personal de la profesora es https://www.iteso.mx/web/general/detalle?group_id=3083477 .\\nEl PROPÓSITO GENERAL del curso es desarrollar habilidades y conocer herramientas para convertir información no estructurada a información estructurada usando técnicas de procesamiento del lenguaje natural y de la inteligencia artificial con fines de visualización, clasificación o análisis de los contenidos. \\nLos PROPÓSITOS ESPECÍFICOS del curso son: Conocer los conceptos básicos de la minería de textos para el tratamiento de texto no estructurado; Aprender a manejar herramientas básicas de procesamiento del lenguaje natural y de la inteligencia artificial para la visualización, clasificación y análisis de textos; Implementar aplicaciones prácticas para la vida real utilizando los conceptos de la minería de textos y las herramientas de procesamiento del lenguaje natural y de la inteligencia artificial.\\nLos requerimientos para las clases en línea son Canvas como LMS (Learning Management System), MS Teams, Cámara web, Micrófono, Buena conexión a Internet; y los requerimientos para el desarrollo de los temas del curso son principalmente: Jupyter Notebook, Python, Nltk.\\nPara el acceso a las plataformas del curso, como son Canvas y MS Teams, se usa la cuenta y contraseña del ITESO.\\nPara mayor información del curso puede dirigirse al correo de contacto: mildreth@iteso.mx o al teléfono de contacto: 3334343669 extensión 3975.\\nEl nombre de la profesora del curso de Minería de Textos es Mildreth Alcaraz.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2310"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "FILE_PATH = \"C:/Users/peter/OneDrive - ITESO/Documents/School Work/Maestría Data Science/Minería de Textos/Dataset Entradas/Corpus_TextMiningCourse.txt\"\n",
    "\n",
    "with open(FILE_PATH, 'r') as f:\n",
    "    doc_raw = f.read()\n",
    "\n",
    "doc_raw # imprime el texto de entrada\n",
    "len(doc_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2. PREPROCESAMIENTO DEL CORPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Crear una función para remover los signos de puntuación. La función recibe una oración y retorna la oración sin signos de puntuación. Si el corpus que se está trabajando contiene enlaces o correos-e, hay que considerarlo aquí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "x = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "def remove_punct_sent(tokenized_sent):\n",
    "    new_sent = []\n",
    "    for token in tokenized_sent.split(' '):\n",
    "        if '@' not in token and 'http' not in token:\n",
    "            new_token = re.sub(x, '', token)\n",
    "        else:\n",
    "            new_token = token\n",
    "        if not new_token == '':\n",
    "            new_sent.append(new_token)\n",
    "    return new_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Crear una función para normalizar por oración:\n",
    "1. Remover la puntuación de la oración (llamando a la función creada en el paso anterior)\n",
    "2. Convertir a minúsculars y aplicar \"stem\" o \"lemmatize\" para cada token de la oración de entrada, sólo si la palabra no es una palabra de parada (stopword)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "stops=stopwords.words('spanish')\n",
    "\n",
    "def sent_norm(sent_):\n",
    "    sent = remove_punct_sent(sent_)\n",
    "    norm_sent = [stemmer.stem(word.lower()) \n",
    "                 for word in sent if word not in stops]\n",
    "    return norm_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Separar el texto plano de entrada en oraciones, es decir, \"tokenize by sentence\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['El curso de Minería de Textos tiene 8 créditos que se traduce a un tiempo de dedicación de 8 horas totales repartidas en 3 horas BCD y 5 horas TIE.',\n",
       " 'BCD significa o es igual a Bajo Conducción Docente.',\n",
       " 'TIE significa o es igual a Tiempo Independiente del Estudiante.',\n",
       " 'La CLAVE DE ASIGNATURA es MSC2499A.',\n",
       " 'Este curso pertenece al programa académico de posgrado de la Maestría en Sistemas Computacionales, en el departamento de Electrónica, Sistemas e Informática.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "doc_sent = sent_tokenize(doc_raw)\n",
    "len(doc_sent)\n",
    "doc_sent[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3. Vectorizar el documento de entrada o corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Obtener el vector TF-IDF utilizando como tokenizador la función para normalizar por oración creada en el paso 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17, 130)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 122)\t0.2054726539058185\n",
      "  (0, 121)\t0.2054726539058185\n",
      "  (0, 119)\t0.1794150561944291\n",
      "  (0, 118)\t0.1794150561944291\n",
      "  (0, 117)\t0.16092689639270452\n",
      "  (0, 108)\t0.2054726539058185\n",
      "  (0, 86)\t0.16092689639270452\n",
      "  (0, 57)\t0.6164179617174554\n",
      "  (0, 41)\t0.2054726539058185\n",
      "  (0, 40)\t0.08517952104272357\n",
      "  (0, 38)\t0.2054726539058185\n",
      "  (0, 19)\t0.1794150561944291\n",
      "  (0, 6)\t0.410945307811637\n",
      "  (0, 4)\t0.2054726539058185\n",
      "  (0, 1)\t0.2054726539058185\n",
      "  (1, 110)\t0.3885691049240456\n",
      "  (1, 61)\t0.3885691049240456\n",
      "  (1, 45)\t0.3885691049240456\n",
      "  (1, 29)\t0.4450034847021449\n",
      "  (1, 19)\t0.3885691049240456\n",
      "  (1, 17)\t0.4450034847021449\n",
      "  (2, 119)\t0.3885691049240456\n",
      "  (2, 118)\t0.3885691049240456\n",
      "  (2, 110)\t0.3885691049240456\n",
      "  (2, 64)\t0.4450034847021449\n",
      "  (2, 61)\t0.3885691049240456\n",
      "  (2, 51)\t0.4450034847021449\n",
      "  (3, 88)\t0.5773502691896257\n",
      "  (3, 26)\t0.5773502691896257\n",
      "  (3, 15)\t0.5773502691896257\n",
      "  (4, 111)\t0.5561071701438545\n",
      "  (4, 103)\t0.27805358507192723\n",
      "  (4, 98)\t0.27805358507192723\n",
      "  (4, 96)\t0.24279143059888036\n",
      "  (4, 77)\t0.27805358507192723\n",
      "  (4, 66)\t0.27805358507192723\n",
      "  (4, 47)\t0.27805358507192723\n",
      "  (4, 42)\t0.27805358507192723\n",
      "  (4, 40)\t0.1152682400816952\n",
      "  (4, 27)\t0.27805358507192723\n",
      "  (4, 7)\t0.27805358507192723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.20547265, 0.        , 0.        , 0.20547265,\n",
       "        0.        , 0.41094531, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.17941506,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.20547265, 0.        ,\n",
       "        0.08517952, 0.20547265, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.61641796, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.1609269 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.20547265, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1609269 , 0.17941506, 0.17941506,\n",
       "        0.        , 0.20547265, 0.20547265, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.44500348, 0.        , 0.3885691 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.44500348,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.3885691 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.3885691 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.3885691 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.44500348, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.3885691 , 0.        , 0.        , 0.44500348,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.3885691 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3885691 , 0.3885691 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.57735027, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.57735027, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.57735027, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.27805359, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.27805359, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.11526824, 0.        , 0.27805359, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.27805359, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.27805359, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.27805359, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.24279143, 0.        , 0.27805359, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.27805359, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.55610717, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(tokenizer=sent_norm)\n",
    "tfidf_vect_fit = tfidf_vect.fit(doc_sent)\n",
    "tfidf_vect_doc = tfidf_vect_fit.transform(doc_sent)\n",
    "tfidf_tokens_doc = tfidf_vect.get_feature_names()\n",
    "\n",
    "tfidf_vect_doc.shape\n",
    "type(tfidf_vect_doc)\n",
    "print(tfidf_vect_doc[0:5][:])\n",
    "tfidf_vect_doc.toarray()[0:5][:]\n",
    "len(tfidf_tokens_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4. Determinar coincidencias manualmente: Función de SALUDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "welcome = {\n",
    "    'hola': '¡Hola!',\n",
    "    'buenos días': '¡Buenos días!',\n",
    "    'oiga': 'Dígame, ¿En qué puedo ayudarle?',\n",
    "    'buen día': '¡Buen día!',\n",
    "    'buenas tardes' : '¡Buenas tardes!',\n",
    "    'buenas noches' : '¡Buenas noches!',\n",
    "    'buena tarde' : '¡Buenas tardes!',\n",
    "    'buena noche' : '¡Buenas noches!',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5. Función para calcular la vectorización de la pregunta del usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Obtener el vector para la pregunta del usuario:\n",
    "1. Función vectorization_q que recibe la pregunta del usuario:\n",
    "2. Normalizar la pregunta del usuario\n",
    "3. Crear un vector de zeros con numpy de tamaño 1xn, n = el número de tokens o características (features) obtenidas en la vectorización del corpus.\n",
    "4. Para cada token obtenido del paso 2, si el token existe dentro del conjunto de tokens o features obtenidos en la vectorización, asignar en la posición correspondiente a ese token en la lista de features del documento vectorizado el valor de acuerdo al tipo de TF-IDF elegido.\n",
    "5. Convertir el vector obtenido en el paso 4, a una matriz csr, la cual correspondera al tfidf de la pregunta del usuario.\n",
    "\n",
    "##### NOTA: Si los valores que se asignan para cada token incluido en la consulta o pregunta del usuario son equivalentes al tipo de TD-IDF elegido para la vectorización del corpus, entonces simplemente se pasa la consulta por la función de transform, de la instancia de tfidf creado y entrenado para el corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorization_q(q):\n",
    "    q_ = tfidf_vect_fit.transform(q)\n",
    "    return q_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Paso 6. Conversación: recepción de saludo, pregunta del usuario y generación de respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Iniciar conversación - chat, informar  salir, y recibir posible saludo.\n",
    "2. Saludar al usuario y dar bienvenida.\n",
    "3. Recibir pregunta del usuario.\n",
    "4. Calcular la similitud entre los vectores TF-IDF de la pregunta del usuario y los TF-IDF de los párrafos del corpus: usando la librería de cosine_similarity de sklearn.metrics.pairwise.\n",
    "5. Ordenar el vector de similitudes obtenido usando argsort. argsort es una matrix de tamaño 1xm, donde m = el número de oraciones que componen el corpus, es decir, la longitud del documento separado por oraciones.\n",
    "6. Obtener el de mayor similtud y retornarlo como respuesta al usuario.\n",
    "7. Invitar al usuario a realizar otra pregunta e ir a 3.\n",
    "8. Despedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot > Bienvenido al chat sobre información del curso de Minería de Textos. Por favor ingresa tu consulta. \n",
      "Si deseas salir teclea la palabra bye\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " dame horarios\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot > El horario del curso es cada Lunes de 7pm a 10pm.\n",
      "\n",
      "Chatbot > ¿Hay algo mas en lo que pueda ayudarte?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " quiero objetivos especificos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot > Los PROPÓSITOS ESPECÍFICOS del curso son: Conocer los conceptos básicos de la minería de textos para el tratamiento de texto no estructurado; Aprender a manejar herramientas básicas de procesamiento del lenguaje natural y de la inteligencia artificial para la visualización, clasificación y análisis de textos; Implementar aplicaciones prácticas para la vida real utilizando los conceptos de la minería de textos y las herramientas de procesamiento del lenguaje natural y de la inteligencia artificial.\n",
      "\n",
      "Chatbot > ¿Hay algo mas en lo que pueda ayudarte?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " alondra es bonita\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot > Disculpa, no he encontrado una respuesta a tu consulta. Para más información, escribe a: help@ctm.iteso.mx\n",
      "Chatbot > ¿Hay algo mas en lo que pueda ayudarte?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " bye\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "print(\"Chatbot > Bienvenido al chat sobre información del curso de Minería de Textos. Por favor ingresa tu consulta. \\nSi deseas salir teclea la palabra bye\")\n",
    "tu = input()\n",
    "\n",
    "while tu != \"bye\":\n",
    "    #tu_norm = sent_norm(tu)\n",
    "    tu_vect_doc = tfidf_vect_fit.transform([tu])\n",
    "    tu_tokens_doc = tfidf_vect.get_feature_names()\n",
    "\n",
    "    cos_sim = cosine_similarity(tu_vect_doc, tfidf_vect_doc)\n",
    "    \n",
    "    if np.sum(cos_sim) == 0:\n",
    "        respuesta = \"Chatbot > Disculpa, no he encontrado una respuesta a tu consulta. Para más información, escribe a: help@ctm.iteso.mx\"\n",
    "        print(respuesta)\n",
    "        print(\"Chatbot > ¿Hay algo mas en lo que pueda ayudarte?\")\n",
    "    else:\n",
    "        idx = np.argmax(cos_sim)\n",
    "        respuesta = doc_sent[idx]\n",
    "        print(\"Chatbot > \" + respuesta + \"\\n\")\n",
    "        print(\"Chatbot > ¿Hay algo mas en lo que pueda ayudarte?\")\n",
    "    tu = input()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo de la dinámica del CHATBOT\n",
    "\n",
    "Chatbot: Bienvenido al chat sobre información del curso de Minería de Textos.\n",
    "Chatbot: Si deseas salir teclea la palabra \"Bye\"\n",
    "Tú: Hola\n",
    "Chatbot: ¡Hola!\n",
    "Chatbot: ¿En qué puedo ayudarte?\n",
    "Tú: objetivos particulares del curso\n",
    "Chatbot: El curso se imparte en el idioma Español.\n",
    "\n",
    "Chatbot: ¿Algo más en lo que pueda ayudarte? \n",
    "Tú: objetivos específicos\n",
    "Chatbot: Los PROPÓSITOS ESPECÍFICOS del curso son: Conocer los conceptos básicos de la minería de textos para el tratamiento de texto no estructurado; Aprender a manejar herramientas básicas de procesamiento del lenguaje natural y de la inteligencia artificial para la visualización, clasificación y análisis de textos; Implementar aplicaciones prácticas para la vida real utilizando los conceptos de la minería de textos y las herramientas de procesamiento del lenguaje natural y de la inteligencia artificial.\n",
    "\n",
    "Chatbot: ¿Algo más en lo que pueda ayudarte? \n",
    "Tú: objetivo general\n",
    "Chatbot: El PROPÓSITO GENERAL del curso es desarrollar habilidades y conocer herramientas para convertir información no estructurada a información estructurada usando técnicas de procesamiento del lenguaje natural y de la inteligencia artificial con fines de visualización, clasificación o análisis de los contenidos.\n",
    "\n",
    "Chatbot: ¿Algo más en lo que pueda ayudarte? \n",
    "Tú: créditos\n",
    "Chatbot: El curso de Minería de Textos tiene 8 créditos que se traduce a un tiempo de dedicación de 8 horas totales repartidas en 3 horas BCD y 5 horas TIE.\n",
    "\n",
    "Chatbot: ¿Algo más en lo que pueda ayudarte? \n",
    "Tú: horario\n",
    "Chatbot: El horario del curso es cada Lunes de 7pm a 10pm.\n",
    "\n",
    "Chatbot: ¿Algo más en lo que pueda ayudarte? \n",
    "Tú: bced\n",
    "Chatbot: Disculpa, no he encontrado una respuesta a tu consulta.\n",
    "Chatbot: Para más información, escribe a: help@ctm.iteso.mx\n",
    "\n",
    "Chatbot: ¿Algo más en lo que pueda ayudarte? \n",
    "Tú: bcd\n",
    "Chatbot: BCD significa o es igual a Bajo Conducción Docente.\n",
    "\n",
    "Chatbot: ¿Algo más en lo que pueda ayudarte? \n",
    "Tú: horas bcd\n",
    "Chatbot: El curso de Minería de Textos tiene 8 créditos que se traduce a un tiempo de dedicación de 8 horas totales repartidas en 3 horas BCD y 5 horas TIE.\n",
    "\n",
    "Chatbot: ¿Algo más en lo que pueda ayudarte? \n",
    "Tú: bye\n",
    "Chatbot: Un gusto atenderte. ¡Hasta pronto!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
